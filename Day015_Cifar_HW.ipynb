{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day015_Cifar_HW.ipynb.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sAkU1OWdbfR",
        "colab_type": "code",
        "outputId": "797a8af9-6ba8-4356-fdf7-db75b1aa0af2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uw2uqOgdmq0n",
        "colab_type": "code",
        "outputId": "f7f3f2ee-c6e8-4b68-943e-28fdb7776300",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print(x_train.shape) #(50000, 32, 32, 3)\n",
        "\n",
        "## Normalize Data\n",
        "def normalize(X_train,X_test):\n",
        "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
        "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
        "        X_train = (X_train-mean)/(std+1e-7)\n",
        "        X_test = (X_test-mean)/(std+1e-7) \n",
        "        return X_train, X_test,mean,std\n",
        "    \n",
        "    \n",
        "## Normalize Training and Testset    \n",
        "x_train, x_test,mean_train,std_train = normalize(x_train, x_test) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n",
            "(50000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gfJOgr2m53d",
        "colab_type": "code",
        "outputId": "620f116f-1727-4096-9bf6-2937e88b8bbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "## OneHot Label 由(None, 1)-(None, 10)\n",
        "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
        "one_hot=OneHotEncoder()\n",
        "y_train=one_hot.fit_transform(y_train).toarray()\n",
        "y_test=one_hot.transform(y_test).toarray()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlRWyC9Pm7dO",
        "colab_type": "code",
        "outputId": "595da2b8-b117-4f41-8e88-5d40a83f8e56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "classifier=Sequential()\n",
        "\n",
        "#卷積組合\n",
        "classifier.add(Convolution2D(32, kernel_size=(3, 3), padding='same',input_shape=(32, 32, 3), activation='relu'))#32,3,3,input_shape=(32,32,3),activation='relu''\n",
        "classifier.add(BatchNormalization(momentum=0.99, epsilon=0.001,))\n",
        "\n",
        "#卷積組合\n",
        "classifier.add(Convolution2D(32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "classifier.add(BatchNormalization(momentum=0.99, epsilon=0.001,))\n",
        "\n",
        "'''自己決定MaxPooling2D放在哪裡'''\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "#卷積組合\n",
        "classifier.add(Convolution2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "classifier.add(BatchNormalization(momentum=0.99, epsilon=0.001,))\n",
        "\n",
        "\n",
        "#卷積組合\n",
        "classifier.add(Convolution2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "classifier.add(BatchNormalization(momentum=0.99, epsilon=0.001,))\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "#卷積組合\n",
        "classifier.add(Convolution2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "classifier.add(BatchNormalization(momentum=0.99, epsilon=0.001,))\n",
        "\n",
        "#卷積組合\n",
        "classifier.add(Convolution2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "classifier.add(BatchNormalization(momentum=0.99, epsilon=0.001,))\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "#卷積組合\n",
        "classifier.add(Convolution2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "classifier.add(BatchNormalization(momentum=0.99, epsilon=0.001,))\n",
        "\n",
        "\n",
        "\n",
        "#卷積組合\n",
        "classifier.add(Convolution2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "classifier.add(BatchNormalization(momentum=0.99, epsilon=0.001,))\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "#卷積組合\n",
        "classifier.add(Convolution2D(512, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "classifier.add(BatchNormalization(momentum=0.99, epsilon=0.001,))\n",
        "\n",
        "\n",
        "#卷積組合\n",
        "classifier.add(Convolution2D(512, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "classifier.add(BatchNormalization(momentum=0.99, epsilon=0.001,))\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "\n",
        "classifier.add(Dropout(0.25))\n",
        "\n",
        "# #flatten\n",
        "classifier.add(Flatten())\n",
        "# #FC\n",
        "classifier.add(Dense(100, activation='relu')) #output_dim=100,activation=relu\n",
        "classifier.add(Dropout(0.5))\n",
        "# #輸出\n",
        "classifier.add(Dense(output_dim=10,activation='softmax'))\n",
        "\n",
        "# #超過兩個就要選categorical_crossentrophy\n",
        "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "classifier.fit(x_train,y_train,batch_size=100,epochs=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:64: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "50000/50000 [==============================] - 21s 416us/step - loss: 1.7197 - acc: 0.3791\n",
            "Epoch 2/100\n",
            "50000/50000 [==============================] - 14s 282us/step - loss: 1.2182 - acc: 0.5815\n",
            "Epoch 3/100\n",
            "50000/50000 [==============================] - 14s 283us/step - loss: 0.9194 - acc: 0.6971\n",
            "Epoch 4/100\n",
            "50000/50000 [==============================] - 14s 280us/step - loss: 0.7375 - acc: 0.7616\n",
            "Epoch 5/100\n",
            "50000/50000 [==============================] - 14s 281us/step - loss: 0.6124 - acc: 0.8043\n",
            "Epoch 6/100\n",
            "50000/50000 [==============================] - 14s 281us/step - loss: 0.5154 - acc: 0.8361\n",
            "Epoch 7/100\n",
            "50000/50000 [==============================] - 14s 281us/step - loss: 0.4296 - acc: 0.8642\n",
            "Epoch 8/100\n",
            "50000/50000 [==============================] - 14s 279us/step - loss: 0.3609 - acc: 0.8844\n",
            "Epoch 9/100\n",
            "50000/50000 [==============================] - 14s 284us/step - loss: 0.3047 - acc: 0.9024\n",
            "Epoch 10/100\n",
            "50000/50000 [==============================] - 14s 282us/step - loss: 0.2589 - acc: 0.9194\n",
            "Epoch 11/100\n",
            "50000/50000 [==============================] - 14s 281us/step - loss: 0.2116 - acc: 0.9338\n",
            "Epoch 12/100\n",
            "50000/50000 [==============================] - 14s 279us/step - loss: 0.1743 - acc: 0.9453\n",
            "Epoch 13/100\n",
            "50000/50000 [==============================] - 14s 279us/step - loss: 0.1492 - acc: 0.9551\n",
            "Epoch 14/100\n",
            "50000/50000 [==============================] - 14s 280us/step - loss: 0.1253 - acc: 0.9617\n",
            "Epoch 15/100\n",
            "50000/50000 [==============================] - 14s 279us/step - loss: 0.1189 - acc: 0.9629\n",
            "Epoch 16/100\n",
            "50000/50000 [==============================] - 14s 280us/step - loss: 0.1095 - acc: 0.9664\n",
            "Epoch 17/100\n",
            "50000/50000 [==============================] - 14s 277us/step - loss: 0.0952 - acc: 0.9706\n",
            "Epoch 18/100\n",
            "50000/50000 [==============================] - 14s 278us/step - loss: 0.0851 - acc: 0.9744\n",
            "Epoch 19/100\n",
            "50000/50000 [==============================] - 14s 280us/step - loss: 0.0786 - acc: 0.9760\n",
            "Epoch 20/100\n",
            "50000/50000 [==============================] - 14s 278us/step - loss: 0.0776 - acc: 0.9759\n",
            "Epoch 21/100\n",
            "50000/50000 [==============================] - 14s 279us/step - loss: 0.0672 - acc: 0.9795\n",
            "Epoch 22/100\n",
            "50000/50000 [==============================] - 14s 282us/step - loss: 0.0662 - acc: 0.9800\n",
            "Epoch 23/100\n",
            "50000/50000 [==============================] - 14s 279us/step - loss: 0.0690 - acc: 0.9790\n",
            "Epoch 24/100\n",
            "50000/50000 [==============================] - 14s 279us/step - loss: 0.0607 - acc: 0.9819\n",
            "Epoch 25/100\n",
            "50000/50000 [==============================] - 14s 278us/step - loss: 0.0552 - acc: 0.9825\n",
            "Epoch 26/100\n",
            "50000/50000 [==============================] - 14s 278us/step - loss: 0.0542 - acc: 0.9834\n",
            "Epoch 27/100\n",
            "50000/50000 [==============================] - 14s 279us/step - loss: 0.0525 - acc: 0.9842\n",
            "Epoch 28/100\n",
            "50000/50000 [==============================] - 14s 278us/step - loss: 0.0467 - acc: 0.9861\n",
            "Epoch 29/100\n",
            "50000/50000 [==============================] - 14s 278us/step - loss: 0.0464 - acc: 0.9854\n",
            "Epoch 30/100\n",
            "50000/50000 [==============================] - 14s 278us/step - loss: 0.0493 - acc: 0.9855\n",
            "Epoch 31/100\n",
            "50000/50000 [==============================] - 14s 279us/step - loss: 0.0429 - acc: 0.9867\n",
            "Epoch 32/100\n",
            "50000/50000 [==============================] - 14s 282us/step - loss: 0.0478 - acc: 0.9854\n",
            "Epoch 33/100\n",
            "50000/50000 [==============================] - 14s 278us/step - loss: 0.0357 - acc: 0.9892\n",
            "Epoch 34/100\n",
            "50000/50000 [==============================] - 14s 277us/step - loss: 0.0345 - acc: 0.9898\n",
            "Epoch 35/100\n",
            "50000/50000 [==============================] - 14s 277us/step - loss: 0.0424 - acc: 0.9871\n",
            "Epoch 36/100\n",
            "50000/50000 [==============================] - 14s 278us/step - loss: 0.0417 - acc: 0.9877\n",
            "Epoch 37/100\n",
            "50000/50000 [==============================] - 14s 279us/step - loss: 0.0344 - acc: 0.9894\n",
            "Epoch 38/100\n",
            "50000/50000 [==============================] - 14s 280us/step - loss: 0.0373 - acc: 0.9883\n",
            "Epoch 39/100\n",
            "50000/50000 [==============================] - 14s 279us/step - loss: 0.0374 - acc: 0.9890\n",
            "Epoch 40/100\n",
            "50000/50000 [==============================] - 14s 281us/step - loss: 0.0321 - acc: 0.9901\n",
            "Epoch 41/100\n",
            "50000/50000 [==============================] - 14s 281us/step - loss: 0.0350 - acc: 0.9893\n",
            "Epoch 42/100\n",
            "50000/50000 [==============================] - 14s 281us/step - loss: 0.0293 - acc: 0.9909\n",
            "Epoch 43/100\n",
            "50000/50000 [==============================] - 14s 281us/step - loss: 0.0303 - acc: 0.9909\n",
            "Epoch 44/100\n",
            "50000/50000 [==============================] - 14s 285us/step - loss: 0.0313 - acc: 0.9912\n",
            "Epoch 45/100\n",
            "50000/50000 [==============================] - 14s 282us/step - loss: 0.0334 - acc: 0.9909\n",
            "Epoch 46/100\n",
            "50000/50000 [==============================] - 14s 283us/step - loss: 0.0301 - acc: 0.9911\n",
            "Epoch 47/100\n",
            "50000/50000 [==============================] - 14s 283us/step - loss: 0.0288 - acc: 0.9913\n",
            "Epoch 48/100\n",
            "50000/50000 [==============================] - 14s 284us/step - loss: 0.0266 - acc: 0.9921\n",
            "Epoch 49/100\n",
            "50000/50000 [==============================] - 14s 283us/step - loss: 0.0276 - acc: 0.9917\n",
            "Epoch 50/100\n",
            "50000/50000 [==============================] - 14s 284us/step - loss: 0.0282 - acc: 0.9915\n",
            "Epoch 51/100\n",
            "50000/50000 [==============================] - 14s 284us/step - loss: 0.0262 - acc: 0.9921\n",
            "Epoch 52/100\n",
            "50000/50000 [==============================] - 14s 284us/step - loss: 0.0257 - acc: 0.9922\n",
            "Epoch 53/100\n",
            "50000/50000 [==============================] - 14s 284us/step - loss: 0.0252 - acc: 0.9919\n",
            "Epoch 54/100\n",
            "50000/50000 [==============================] - 14s 287us/step - loss: 0.0263 - acc: 0.9923\n",
            "Epoch 55/100\n",
            "50000/50000 [==============================] - 14s 285us/step - loss: 0.0209 - acc: 0.9941\n",
            "Epoch 56/100\n",
            "50000/50000 [==============================] - 14s 284us/step - loss: 0.0256 - acc: 0.9932\n",
            "Epoch 57/100\n",
            "50000/50000 [==============================] - 14s 285us/step - loss: 0.0214 - acc: 0.9933\n",
            "Epoch 58/100\n",
            "50000/50000 [==============================] - 14s 284us/step - loss: 0.0281 - acc: 0.9917\n",
            "Epoch 59/100\n",
            "50000/50000 [==============================] - 14s 285us/step - loss: 0.0195 - acc: 0.9940\n",
            "Epoch 60/100\n",
            "50000/50000 [==============================] - 14s 284us/step - loss: 0.0213 - acc: 0.9933\n",
            "Epoch 61/100\n",
            "50000/50000 [==============================] - 14s 284us/step - loss: 0.0240 - acc: 0.9935\n",
            "Epoch 62/100\n",
            "50000/50000 [==============================] - 14s 284us/step - loss: 0.0215 - acc: 0.9931\n",
            "Epoch 63/100\n",
            "50000/50000 [==============================] - 14s 284us/step - loss: 0.0189 - acc: 0.9945\n",
            "Epoch 64/100\n",
            "50000/50000 [==============================] - 14s 285us/step - loss: 0.0191 - acc: 0.9950\n",
            "Epoch 65/100\n",
            "50000/50000 [==============================] - 14s 287us/step - loss: 0.0236 - acc: 0.9928\n",
            "Epoch 66/100\n",
            "50000/50000 [==============================] - 14s 286us/step - loss: 0.0229 - acc: 0.9939\n",
            "Epoch 67/100\n",
            "50000/50000 [==============================] - 14s 286us/step - loss: 0.0224 - acc: 0.9935\n",
            "Epoch 68/100\n",
            "50000/50000 [==============================] - 14s 284us/step - loss: 0.0146 - acc: 0.9952\n",
            "Epoch 69/100\n",
            "50000/50000 [==============================] - 14s 284us/step - loss: 0.0145 - acc: 0.9954\n",
            "Epoch 70/100\n",
            "50000/50000 [==============================] - 14s 285us/step - loss: 0.0187 - acc: 0.9945\n",
            "Epoch 71/100\n",
            "50000/50000 [==============================] - 14s 286us/step - loss: 0.0208 - acc: 0.9937\n",
            "Epoch 72/100\n",
            "50000/50000 [==============================] - 14s 286us/step - loss: 0.0184 - acc: 0.9948\n",
            "Epoch 73/100\n",
            "50000/50000 [==============================] - 14s 286us/step - loss: 0.0178 - acc: 0.9945\n",
            "Epoch 74/100\n",
            "50000/50000 [==============================] - 14s 287us/step - loss: 0.0203 - acc: 0.9941\n",
            "Epoch 75/100\n",
            "50000/50000 [==============================] - 14s 287us/step - loss: 0.0151 - acc: 0.9952\n",
            "Epoch 76/100\n",
            "50000/50000 [==============================] - 14s 284us/step - loss: 0.0170 - acc: 0.9949\n",
            "Epoch 77/100\n",
            "50000/50000 [==============================] - 14s 281us/step - loss: 0.0118 - acc: 0.9963\n",
            "Epoch 78/100\n",
            "50000/50000 [==============================] - 14s 284us/step - loss: 0.0173 - acc: 0.9948\n",
            "Epoch 79/100\n",
            "50000/50000 [==============================] - 14s 286us/step - loss: 0.0156 - acc: 0.9954\n",
            "Epoch 80/100\n",
            "50000/50000 [==============================] - 14s 285us/step - loss: 0.0181 - acc: 0.9948\n",
            "Epoch 81/100\n",
            "50000/50000 [==============================] - 14s 285us/step - loss: 0.0174 - acc: 0.9949\n",
            "Epoch 82/100\n",
            "50000/50000 [==============================] - 14s 285us/step - loss: 0.0150 - acc: 0.9956\n",
            "Epoch 83/100\n",
            "50000/50000 [==============================] - 14s 287us/step - loss: 0.0180 - acc: 0.9947\n",
            "Epoch 84/100\n",
            "50000/50000 [==============================] - 14s 283us/step - loss: 0.0165 - acc: 0.9950\n",
            "Epoch 85/100\n",
            "50000/50000 [==============================] - 14s 285us/step - loss: 0.0144 - acc: 0.9956\n",
            "Epoch 86/100\n",
            "50000/50000 [==============================] - 14s 284us/step - loss: 0.0106 - acc: 0.9969\n",
            "Epoch 87/100\n",
            "50000/50000 [==============================] - 14s 286us/step - loss: 0.0155 - acc: 0.9958\n",
            "Epoch 88/100\n",
            "50000/50000 [==============================] - 14s 284us/step - loss: 0.0167 - acc: 0.9953\n",
            "Epoch 89/100\n",
            "50000/50000 [==============================] - 14s 283us/step - loss: 0.0124 - acc: 0.9964\n",
            "Epoch 90/100\n",
            "50000/50000 [==============================] - 14s 283us/step - loss: 0.0133 - acc: 0.9963\n",
            "Epoch 91/100\n",
            "50000/50000 [==============================] - 14s 283us/step - loss: 0.0138 - acc: 0.9960\n",
            "Epoch 92/100\n",
            "50000/50000 [==============================] - 14s 283us/step - loss: 0.0161 - acc: 0.9955\n",
            "Epoch 93/100\n",
            "50000/50000 [==============================] - 14s 282us/step - loss: 0.0161 - acc: 0.9954\n",
            "Epoch 94/100\n",
            "50000/50000 [==============================] - 14s 282us/step - loss: 0.0123 - acc: 0.9963\n",
            "Epoch 95/100\n",
            "50000/50000 [==============================] - 14s 284us/step - loss: 0.0171 - acc: 0.9954\n",
            "Epoch 96/100\n",
            "50000/50000 [==============================] - 14s 283us/step - loss: 0.0118 - acc: 0.9964\n",
            "Epoch 97/100\n",
            "50000/50000 [==============================] - 14s 285us/step - loss: 0.0112 - acc: 0.9966\n",
            "Epoch 98/100\n",
            "50000/50000 [==============================] - 14s 282us/step - loss: 0.0170 - acc: 0.9952\n",
            "Epoch 99/100\n",
            "50000/50000 [==============================] - 14s 282us/step - loss: 0.0164 - acc: 0.9954\n",
            "Epoch 100/100\n",
            "50000/50000 [==============================] - 14s 282us/step - loss: 0.0130 - acc: 0.9962\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fde8967e198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNCajMBIGVv_",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFh_DaEV6aUv",
        "colab_type": "code",
        "outputId": "22e006c0-ef22-4b65-b472-43bac73aacb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "scores = classifier.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 4s 432us/step\n",
            "Test loss: 0.8927066890120506\n",
            "Test accuracy: 0.8266\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}