{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day015_Cifar_HW.ipynb.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sAkU1OWdbfR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "797a8af9-6ba8-4356-fdf7-db75b1aa0af2"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uw2uqOgdmq0n",
        "colab_type": "code",
        "outputId": "f7f3f2ee-c6e8-4b68-943e-28fdb7776300",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print(x_train.shape) #(50000, 32, 32, 3)\n",
        "\n",
        "## Normalize Data\n",
        "def normalize(X_train,X_test):\n",
        "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
        "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
        "        X_train = (X_train-mean)/(std+1e-7)\n",
        "        X_test = (X_test-mean)/(std+1e-7) \n",
        "        return X_train, X_test,mean,std\n",
        "    \n",
        "    \n",
        "## Normalize Training and Testset    \n",
        "x_train, x_test,mean_train,std_train = normalize(x_train, x_test) "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n",
            "(50000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gfJOgr2m53d",
        "colab_type": "code",
        "outputId": "620f116f-1727-4096-9bf6-2937e88b8bbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "## OneHot Label 由(None, 1)-(None, 10)\n",
        "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
        "one_hot=OneHotEncoder()\n",
        "y_train=one_hot.fit_transform(y_train).toarray()\n",
        "y_test=one_hot.transform(y_test).toarray()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlRWyC9Pm7dO",
        "colab_type": "code",
        "outputId": "09820cc5-222b-4a05-fa01-dd4455f8a283",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "classifier=Sequential()\n",
        "\n",
        "#卷積組合\n",
        "classifier.add(Convolution2D(32, kernel_size=(3, 3), padding='same',input_shape=(32, 32, 3), activation='relu'))#32,3,3,input_shape=(32,32,3),activation='relu''\n",
        "classifier.add(BatchNormalization(momentum=0.99, epsilon=0.001,))\n",
        "\n",
        "'''自己決定MaxPooling2D放在哪裡'''\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "#卷積組合\n",
        "classifier.add(Convolution2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "classifier.add(BatchNormalization(momentum=0.99, epsilon=0.001,))\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "#卷積組合\n",
        "classifier.add(Convolution2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "classifier.add(BatchNormalization(momentum=0.99, epsilon=0.001,))\n",
        "\n",
        "\n",
        "#卷積組合\n",
        "classifier.add(Convolution2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "classifier.add(BatchNormalization(momentum=0.99, epsilon=0.001,))\n",
        "\n",
        "\n",
        "#卷積組合\n",
        "classifier.add(Convolution2D(512, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "classifier.add(BatchNormalization(momentum=0.99, epsilon=0.001,))\n",
        "\n",
        "classifier.add(Dropout(0.25))\n",
        "\n",
        "# #flatten\n",
        "classifier.add(Flatten())\n",
        "# #FC\n",
        "classifier.add(Dense(100, activation='relu')) #output_dim=100,activation=relu\n",
        "classifier.add(Dropout(0.5))\n",
        "# #輸出\n",
        "classifier.add(Dense(output_dim=10,activation='softmax'))\n",
        "\n",
        "# #超過兩個就要選categorical_crossentrophy\n",
        "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "classifier.fit(x_train,y_train,batch_size=100,epochs=50)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 12s 234us/step - loss: 2.1068 - acc: 0.2049\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 10s 201us/step - loss: 1.9037 - acc: 0.2543\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 10s 198us/step - loss: 1.7794 - acc: 0.2972\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 10s 199us/step - loss: 1.7387 - acc: 0.3197\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 10s 202us/step - loss: 1.6891 - acc: 0.3345\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 10s 199us/step - loss: 1.5892 - acc: 0.3919\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 10s 198us/step - loss: 1.4665 - acc: 0.4495\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 10s 198us/step - loss: 1.3372 - acc: 0.5172\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 10s 198us/step - loss: 1.2146 - acc: 0.5727\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 10s 198us/step - loss: 1.0792 - acc: 0.6321\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 10s 199us/step - loss: 0.9385 - acc: 0.6764\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 10s 199us/step - loss: 0.8416 - acc: 0.7102\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 10s 198us/step - loss: 0.7468 - acc: 0.7447\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 10s 200us/step - loss: 0.6585 - acc: 0.7768\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 10s 200us/step - loss: 0.5811 - acc: 0.8054\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 10s 198us/step - loss: 0.5076 - acc: 0.8290\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 10s 196us/step - loss: 0.4573 - acc: 0.8465\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 10s 197us/step - loss: 0.4060 - acc: 0.8649\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 10s 197us/step - loss: 0.3659 - acc: 0.8778\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 10s 198us/step - loss: 0.3341 - acc: 0.8885\n",
            "Epoch 21/50\n",
            "50000/50000 [==============================] - 10s 198us/step - loss: 0.3053 - acc: 0.8989\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 10s 199us/step - loss: 0.2721 - acc: 0.9110\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 10s 197us/step - loss: 0.2454 - acc: 0.9175\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 10s 198us/step - loss: 0.2211 - acc: 0.9279\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 10s 197us/step - loss: 0.2227 - acc: 0.9285\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 10s 196us/step - loss: 0.2035 - acc: 0.9345\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 10s 197us/step - loss: 0.1978 - acc: 0.9354\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 10s 197us/step - loss: 0.1867 - acc: 0.9413\n",
            "Epoch 29/50\n",
            "50000/50000 [==============================] - 10s 197us/step - loss: 0.1771 - acc: 0.9445\n",
            "Epoch 30/50\n",
            "50000/50000 [==============================] - 10s 196us/step - loss: 0.1712 - acc: 0.9473\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 10s 197us/step - loss: 0.1640 - acc: 0.9500\n",
            "Epoch 32/50\n",
            "50000/50000 [==============================] - 10s 196us/step - loss: 0.1495 - acc: 0.9534\n",
            "Epoch 33/50\n",
            "50000/50000 [==============================] - 10s 196us/step - loss: 0.1353 - acc: 0.9577\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 10s 197us/step - loss: 0.1402 - acc: 0.9569\n",
            "Epoch 35/50\n",
            "50000/50000 [==============================] - 10s 197us/step - loss: 0.1380 - acc: 0.9562\n",
            "Epoch 36/50\n",
            "50000/50000 [==============================] - 10s 198us/step - loss: 0.1270 - acc: 0.9607\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 10s 196us/step - loss: 0.1260 - acc: 0.9622\n",
            "Epoch 38/50\n",
            "50000/50000 [==============================] - 10s 197us/step - loss: 0.1131 - acc: 0.9665\n",
            "Epoch 39/50\n",
            "50000/50000 [==============================] - 10s 195us/step - loss: 0.1136 - acc: 0.9663\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 10s 196us/step - loss: 0.1192 - acc: 0.9649\n",
            "Epoch 41/50\n",
            "50000/50000 [==============================] - 10s 196us/step - loss: 0.1168 - acc: 0.9652\n",
            "Epoch 42/50\n",
            "50000/50000 [==============================] - 10s 195us/step - loss: 0.0971 - acc: 0.9708\n",
            "Epoch 43/50\n",
            "50000/50000 [==============================] - 10s 197us/step - loss: 0.1013 - acc: 0.9695\n",
            "Epoch 44/50\n",
            "50000/50000 [==============================] - 10s 197us/step - loss: 0.1082 - acc: 0.9681\n",
            "Epoch 45/50\n",
            "50000/50000 [==============================] - 10s 195us/step - loss: 0.0996 - acc: 0.9703\n",
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 10s 199us/step - loss: 0.1040 - acc: 0.9693\n",
            "Epoch 47/50\n",
            "50000/50000 [==============================] - 10s 196us/step - loss: 0.0884 - acc: 0.9740\n",
            "Epoch 48/50\n",
            "50000/50000 [==============================] - 10s 196us/step - loss: 0.0915 - acc: 0.9733\n",
            "Epoch 49/50\n",
            "50000/50000 [==============================] - 10s 195us/step - loss: 0.0870 - acc: 0.9754\n",
            "Epoch 50/50\n",
            "50000/50000 [==============================] - 10s 195us/step - loss: 0.0807 - acc: 0.9752\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdfa46b78d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNCajMBIGVv_",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFh_DaEV6aUv",
        "colab_type": "code",
        "outputId": "d5ddd032-3597-41c1-d705-a45e07a3e285",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "scores = classifier.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 2s 173us/step\n",
            "Test loss: 1.1808536009788513\n",
            "Test accuracy: 0.8139\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}